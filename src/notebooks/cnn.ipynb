{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8581502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "project_root = os.path.dirname(os.path.abspath('..')) \n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from src.NeuralNetwork import NeuralNetwork\n",
    "from src.layers import ConvolutionalLayer, FlattenLayer, \\\n",
    "                       DenseLayer, MaxPoolingLayer, ReLULayer, \\\n",
    "                       SigmoidLayer, SoftmaxLayer, ResidualBlock, BatchNormalizationLayer\n",
    "from data.MnistDataloader import MnistDataloader\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de883f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../../data/input'\n",
    "training_images_filepath = join(input_path, '../../data/mnist/train-images-idx3-ubyte/train-images-idx3-ubyte')\n",
    "training_labels_filepath = join(input_path, '../../data/mnist/train-labels-idx1-ubyte/train-labels-idx1-ubyte')\n",
    "test_images_filepath = join(input_path, '../../data/mnist/t10k-images-idx3-ubyte/t10k-images-idx3-ubyte')\n",
    "test_labels_filepath = join(input_path, '../../data/mnist/t10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')\n",
    "\n",
    "#\n",
    "# Helper function to show a list of images with their relating titles\n",
    "#\n",
    "def show_images(images, title_texts):\n",
    "    cols = 5\n",
    "    rows = int(len(images)/cols) + 1\n",
    "    plt.figure(figsize=(30,20))\n",
    "    index = 1    \n",
    "    for x in zip(images, title_texts):        \n",
    "        image = x[0]        \n",
    "        title_text = x[1]\n",
    "        plt.subplot(rows, cols, index)        \n",
    "        plt.imshow(image, cmap=plt.cm.gray)\n",
    "        if (title_text != ''):\n",
    "            plt.title(title_text, fontsize = 15);        \n",
    "        index += 1\n",
    "\n",
    "#\n",
    "# Load MINST dataset\n",
    "#\n",
    "mnist_dataloader = MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)\n",
    "(x_train, y_train), (x_test, y_test) = mnist_dataloader.load_data()\n",
    "x_train = np.expand_dims(np.array(x_train), axis=1)\n",
    "y_train = np.expand_dims(np.array(y_train), axis=1)\n",
    "x_test = np.expand_dims(np.array(x_test), axis=1)\n",
    "y_test = np.expand_dims(np.array(y_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f227496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (60000, 1, 28, 28)\n",
      "test: (10000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float64') / 255.0\n",
    "x_test = x_test.astype('float64') / 255.0\n",
    "\n",
    "print(f\"train: {x_train.shape}\")\n",
    "print(f\"test: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc8ce904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (60000, 1)\n",
      "test: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"train: {y_train.shape}\")\n",
    "print(f\"test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3a25526",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_y_train = y_train\n",
    "old_y_test = y_test\n",
    "\n",
    "y_train = np.zeros((10, old_y_train.shape[0]))\n",
    "y_test = np.zeros((10, old_y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d13c0c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 60000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "245793e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, value in enumerate(old_y_train):\n",
    "  y_train[value, idx] = 1\n",
    "  \n",
    "for idx, value in enumerate(old_y_test):\n",
    "  y_test[value, idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f24c79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f233a690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_model(layers, filename=\"model.pkl\"):\n",
    "  with open(filename, \"wb\") as f:\n",
    "      pickle.dump(layers, f)\n",
    "  print(f\"Model saved to {filename}\")\n",
    "  \n",
    "def load_model(filename=\"model.pkl\"):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42e973ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "    ConvolutionalLayer(name=\"Conv1\", next_act_layer=\"relu\", output_channels_dim=32),\n",
    "    ReLULayer(name=\"ReLU1\"), \n",
    "    MaxPoolingLayer(name=\"Maxpool1\"),\n",
    "\n",
    "    ConvolutionalLayer(name=\"Conv2\", next_act_layer=\"relu\", output_channels_dim=64),\n",
    "    ReLULayer(name=\"ReLU2\"), \n",
    "    MaxPoolingLayer(name=\"Maxpool2\"),\n",
    "\n",
    "    FlattenLayer(name=\"Flatten1\"),\n",
    "\n",
    "    DenseLayer(name=\"Dense1\", next_act_layer=\"softmax\", output_dim=10),\n",
    "    SoftmaxLayer(name=\"Softmax1\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47250a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(\n",
    "  layers = layers,\n",
    "  loss_type=\"cce\",\n",
    "  optimizer_type=\"adam\",\n",
    "  seed=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41571af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.build((\n",
    "  x_train.shape[1],\n",
    "  x_train.shape[2],\n",
    "  x_train.shape[3]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02790fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 0: Loss = 15.0350 | Acc = 10.16%\n",
      "Epoch 0, Batch 1: Loss = 15.3729 | Acc = 14.45%\n",
      "Epoch 0, Batch 2: Loss = 14.4804 | Acc = 10.94%\n",
      "Epoch 0, Batch 3: Loss = 12.4352 | Acc = 17.19%\n",
      "Epoch 0, Batch 4: Loss = 13.0272 | Acc = 18.75%\n",
      "Epoch 0, Batch 5: Loss = 10.5458 | Acc = 25.00%\n",
      "Epoch 0, Batch 6: Loss = 8.9443 | Acc = 32.81%\n",
      "Epoch 0, Batch 7: Loss = 11.2772 | Acc = 20.70%\n",
      "Epoch 0, Batch 8: Loss = 7.1489 | Acc = 35.55%\n",
      "Epoch 0, Batch 9: Loss = 6.4926 | Acc = 45.70%\n",
      "Epoch 0, Batch 10: Loss = 7.9713 | Acc = 42.97%\n",
      "Epoch 0, Batch 11: Loss = 7.7490 | Acc = 44.14%\n",
      "Epoch 0, Batch 12: Loss = 6.3421 | Acc = 49.22%\n",
      "Epoch 0, Batch 13: Loss = 3.6856 | Acc = 51.17%\n",
      "Epoch 0, Batch 14: Loss = 2.4289 | Acc = 56.25%\n",
      "Epoch 0, Batch 15: Loss = 4.6089 | Acc = 43.36%\n",
      "Epoch 0, Batch 16: Loss = 5.9959 | Acc = 34.38%\n",
      "Epoch 0, Batch 17: Loss = 4.0381 | Acc = 44.14%\n",
      "Epoch 0, Batch 18: Loss = 3.2306 | Acc = 52.73%\n",
      "Epoch 0, Batch 19: Loss = 2.8815 | Acc = 60.94%\n",
      "Epoch 0, Batch 20: Loss = 2.8140 | Acc = 62.11%\n",
      "Epoch 0, Batch 21: Loss = 2.2113 | Acc = 66.02%\n",
      "Epoch 0, Batch 22: Loss = 2.6489 | Acc = 62.89%\n",
      "Epoch 0, Batch 23: Loss = 2.4224 | Acc = 65.23%\n",
      "Epoch 0, Batch 24: Loss = 2.3787 | Acc = 64.84%\n",
      "Epoch 0, Batch 25: Loss = 1.9874 | Acc = 69.92%\n",
      "Epoch 0, Batch 26: Loss = 1.7449 | Acc = 69.14%\n",
      "Epoch 0, Batch 27: Loss = 1.8208 | Acc = 70.31%\n",
      "Epoch 0, Batch 28: Loss = 1.6693 | Acc = 71.48%\n",
      "Epoch 0, Batch 29: Loss = 1.7090 | Acc = 72.27%\n",
      "Epoch 0, Batch 30: Loss = 2.0581 | Acc = 66.80%\n",
      "Epoch 0, Batch 31: Loss = 1.4206 | Acc = 73.05%\n",
      "Epoch 0, Batch 32: Loss = 1.8183 | Acc = 67.19%\n",
      "Epoch 0, Batch 33: Loss = 1.1430 | Acc = 80.86%\n",
      "Epoch 0, Batch 34: Loss = 1.3364 | Acc = 77.73%\n",
      "Epoch 0, Batch 35: Loss = 1.3892 | Acc = 74.61%\n",
      "Epoch 0, Batch 36: Loss = 1.0799 | Acc = 80.86%\n",
      "Epoch 0, Batch 37: Loss = 1.0554 | Acc = 81.25%\n",
      "Epoch 0, Batch 38: Loss = 0.7862 | Acc = 84.77%\n",
      "Epoch 0, Batch 39: Loss = 1.0498 | Acc = 81.25%\n",
      "Epoch 0, Batch 40: Loss = 0.9722 | Acc = 80.86%\n",
      "Epoch 0, Batch 41: Loss = 1.2375 | Acc = 78.12%\n",
      "Epoch 0, Batch 42: Loss = 1.1580 | Acc = 79.30%\n",
      "Epoch 0, Batch 43: Loss = 0.7666 | Acc = 83.20%\n",
      "Epoch 0, Batch 44: Loss = 1.0246 | Acc = 82.03%\n",
      "Epoch 0, Batch 45: Loss = 0.9827 | Acc = 82.42%\n",
      "Epoch 0, Batch 46: Loss = 1.1311 | Acc = 78.52%\n",
      "Epoch 0, Batch 47: Loss = 0.8822 | Acc = 82.81%\n",
      "Epoch 0, Batch 48: Loss = 0.8105 | Acc = 81.25%\n",
      "Epoch 0, Batch 49: Loss = 1.1004 | Acc = 80.47%\n",
      "Epoch 0, Batch 50: Loss = 1.1300 | Acc = 77.73%\n",
      "Epoch 0, Batch 51: Loss = 1.2234 | Acc = 78.12%\n",
      "Epoch 0, Batch 52: Loss = 0.8335 | Acc = 83.59%\n",
      "Epoch 0, Batch 53: Loss = 0.8163 | Acc = 83.98%\n",
      "Epoch 0, Batch 54: Loss = 0.8684 | Acc = 83.59%\n",
      "Epoch 0, Batch 55: Loss = 0.8109 | Acc = 83.20%\n",
      "Epoch 0, Batch 56: Loss = 0.8633 | Acc = 80.08%\n",
      "Epoch 0, Batch 57: Loss = 0.8110 | Acc = 84.38%\n",
      "Epoch 0, Batch 58: Loss = 0.8632 | Acc = 82.81%\n",
      "Epoch 0, Batch 59: Loss = 0.6599 | Acc = 86.33%\n",
      "Epoch 0, Batch 60: Loss = 0.9480 | Acc = 82.81%\n",
      "Epoch 0, Batch 61: Loss = 0.9186 | Acc = 82.81%\n",
      "Epoch 0, Batch 62: Loss = 0.9816 | Acc = 82.81%\n",
      "Epoch 0, Batch 63: Loss = 0.9022 | Acc = 82.81%\n",
      "Epoch 0, Batch 64: Loss = 0.9546 | Acc = 81.64%\n",
      "Epoch 0, Batch 65: Loss = 0.7928 | Acc = 86.72%\n",
      "Epoch 0, Batch 66: Loss = 0.8587 | Acc = 83.20%\n",
      "Epoch 0, Batch 67: Loss = 0.8928 | Acc = 84.38%\n",
      "Epoch 0, Batch 68: Loss = 0.6619 | Acc = 82.81%\n",
      "Epoch 0, Batch 69: Loss = 0.7978 | Acc = 81.25%\n",
      "Epoch 0, Batch 70: Loss = 0.7915 | Acc = 83.59%\n",
      "Epoch 0, Batch 71: Loss = 0.8624 | Acc = 84.38%\n",
      "Epoch 0, Batch 72: Loss = 0.6123 | Acc = 85.94%\n",
      "Epoch 0, Batch 73: Loss = 0.9339 | Acc = 80.08%\n",
      "Epoch 0, Batch 74: Loss = 1.1224 | Acc = 77.73%\n",
      "Epoch 0, Batch 75: Loss = 0.7064 | Acc = 86.72%\n",
      "Epoch 0, Batch 76: Loss = 1.0005 | Acc = 81.64%\n",
      "Epoch 0, Batch 77: Loss = 0.6789 | Acc = 83.98%\n",
      "Epoch 0, Batch 78: Loss = 0.8116 | Acc = 85.16%\n",
      "Epoch 0, Batch 79: Loss = 0.7034 | Acc = 84.38%\n",
      "Epoch 0, Batch 80: Loss = 0.6085 | Acc = 86.72%\n",
      "Epoch 0, Batch 81: Loss = 1.2080 | Acc = 81.25%\n",
      "Epoch 0, Batch 82: Loss = 0.8670 | Acc = 83.20%\n",
      "Epoch 0, Batch 83: Loss = 0.6366 | Acc = 83.98%\n",
      "Epoch 0, Batch 84: Loss = 0.5385 | Acc = 85.94%\n",
      "Epoch 0, Batch 85: Loss = 0.7515 | Acc = 85.16%\n",
      "Epoch 0, Batch 86: Loss = 0.9229 | Acc = 81.25%\n",
      "Epoch 0, Batch 87: Loss = 0.6150 | Acc = 84.77%\n",
      "Epoch 0, Batch 88: Loss = 0.6677 | Acc = 85.16%\n",
      "Epoch 0, Batch 89: Loss = 0.5086 | Acc = 87.11%\n",
      "Epoch 0, Batch 90: Loss = 0.5722 | Acc = 84.38%\n",
      "Epoch 0, Batch 91: Loss = 0.6521 | Acc = 85.94%\n",
      "Epoch 0, Batch 92: Loss = 0.5940 | Acc = 85.94%\n",
      "Epoch 0, Batch 93: Loss = 0.7419 | Acc = 84.38%\n",
      "Epoch 0, Batch 94: Loss = 0.4519 | Acc = 88.67%\n",
      "Epoch 0, Batch 95: Loss = 0.5366 | Acc = 87.11%\n",
      "Epoch 0, Batch 96: Loss = 0.7224 | Acc = 84.38%\n",
      "Epoch 0, Batch 97: Loss = 0.7555 | Acc = 84.77%\n",
      "Epoch 0, Batch 98: Loss = 0.5153 | Acc = 85.94%\n",
      "Epoch 0, Batch 99: Loss = 0.6041 | Acc = 90.62%\n",
      "Epoch 0, Batch 100: Loss = 0.7929 | Acc = 81.64%\n",
      "Epoch 0, Batch 101: Loss = 0.4388 | Acc = 89.45%\n",
      "Epoch 0, Batch 102: Loss = 0.5489 | Acc = 87.89%\n",
      "Epoch 0, Batch 103: Loss = 0.7088 | Acc = 85.94%\n",
      "Epoch 0, Batch 104: Loss = 0.4575 | Acc = 88.28%\n",
      "Epoch 0, Batch 105: Loss = 0.9139 | Acc = 84.77%\n",
      "Epoch 0, Batch 106: Loss = 0.6406 | Acc = 84.77%\n",
      "Epoch 0, Batch 107: Loss = 0.6379 | Acc = 88.67%\n",
      "Epoch 0, Batch 108: Loss = 0.8901 | Acc = 81.64%\n",
      "Epoch 0, Batch 109: Loss = 0.6290 | Acc = 89.84%\n",
      "Epoch 0, Batch 110: Loss = 0.4404 | Acc = 89.84%\n",
      "Epoch 0, Batch 111: Loss = 0.5510 | Acc = 88.67%\n",
      "Epoch 0, Batch 112: Loss = 0.2763 | Acc = 92.19%\n",
      "Epoch 0, Batch 113: Loss = 1.0102 | Acc = 84.38%\n",
      "Epoch 0, Batch 114: Loss = 0.6000 | Acc = 87.89%\n",
      "Epoch 0, Batch 115: Loss = 0.5811 | Acc = 85.55%\n",
      "Epoch 0, Batch 116: Loss = 0.6384 | Acc = 87.50%\n",
      "Epoch 0, Batch 117: Loss = 0.7821 | Acc = 85.55%\n",
      "Epoch 0, Batch 118: Loss = 0.7764 | Acc = 87.11%\n",
      "Epoch 0, Batch 119: Loss = 0.4349 | Acc = 88.28%\n",
      "Epoch 0, Batch 120: Loss = 0.7820 | Acc = 87.50%\n",
      "Epoch 0, Batch 121: Loss = 0.6464 | Acc = 83.98%\n",
      "Epoch 0, Batch 122: Loss = 0.6028 | Acc = 87.50%\n",
      "Epoch 0, Batch 123: Loss = 0.6205 | Acc = 83.98%\n",
      "Epoch 0, Batch 124: Loss = 0.7643 | Acc = 85.94%\n",
      "Epoch 0, Batch 125: Loss = 0.7829 | Acc = 83.59%\n",
      "Epoch 0, Batch 126: Loss = 0.2924 | Acc = 91.41%\n",
      "Epoch 0, Batch 127: Loss = 0.6196 | Acc = 88.67%\n",
      "Epoch 0, Batch 128: Loss = 0.5523 | Acc = 89.84%\n",
      "Epoch 0, Batch 129: Loss = 0.6583 | Acc = 84.38%\n",
      "Epoch 0, Batch 130: Loss = 0.7674 | Acc = 84.38%\n",
      "Epoch 0, Batch 131: Loss = 0.7398 | Acc = 85.55%\n",
      "Epoch 0, Batch 132: Loss = 0.7142 | Acc = 84.38%\n",
      "Epoch 0, Batch 133: Loss = 0.5904 | Acc = 85.16%\n",
      "Epoch 0, Batch 134: Loss = 0.5518 | Acc = 89.45%\n",
      "Epoch 0, Batch 135: Loss = 0.7272 | Acc = 86.72%\n",
      "Epoch 0, Batch 136: Loss = 0.5375 | Acc = 88.67%\n",
      "Epoch 0, Batch 137: Loss = 0.4476 | Acc = 89.06%\n",
      "Epoch 0, Batch 138: Loss = 0.3983 | Acc = 91.80%\n",
      "Epoch 0, Batch 139: Loss = 0.6155 | Acc = 86.33%\n",
      "Epoch 0, Batch 140: Loss = 0.5839 | Acc = 87.11%\n",
      "Epoch 0, Batch 141: Loss = 0.4523 | Acc = 89.45%\n",
      "Epoch 0, Batch 142: Loss = 0.4824 | Acc = 89.06%\n",
      "Epoch 0, Batch 143: Loss = 0.4232 | Acc = 89.06%\n",
      "Epoch 0, Batch 144: Loss = 0.4979 | Acc = 90.23%\n",
      "Epoch 0, Batch 145: Loss = 0.5229 | Acc = 90.62%\n",
      "Epoch 0, Batch 146: Loss = 0.3772 | Acc = 91.41%\n",
      "Epoch 0, Batch 147: Loss = 0.4091 | Acc = 90.62%\n",
      "Epoch 0, Batch 148: Loss = 0.5423 | Acc = 88.67%\n",
      "Epoch 0, Batch 149: Loss = 0.7699 | Acc = 85.16%\n",
      "Epoch 0, Batch 150: Loss = 0.5697 | Acc = 86.72%\n",
      "Epoch 0, Batch 151: Loss = 0.5487 | Acc = 87.89%\n",
      "Epoch 0, Batch 152: Loss = 0.4960 | Acc = 87.11%\n",
      "Epoch 0, Batch 153: Loss = 0.5429 | Acc = 86.72%\n",
      "Epoch 0, Batch 154: Loss = 0.5840 | Acc = 85.55%\n",
      "Epoch 0, Batch 155: Loss = 0.6298 | Acc = 89.45%\n",
      "Epoch 0, Batch 156: Loss = 0.6028 | Acc = 87.89%\n",
      "Epoch 0, Batch 157: Loss = 0.3970 | Acc = 88.28%\n",
      "Epoch 0, Batch 158: Loss = 0.3145 | Acc = 91.80%\n",
      "Epoch 0, Batch 159: Loss = 0.6071 | Acc = 87.11%\n",
      "Epoch 0, Batch 160: Loss = 0.7161 | Acc = 85.55%\n",
      "Epoch 0, Batch 161: Loss = 0.4899 | Acc = 89.84%\n",
      "Epoch 0, Batch 162: Loss = 0.6702 | Acc = 89.06%\n",
      "Epoch 0, Batch 163: Loss = 0.4438 | Acc = 89.45%\n",
      "Epoch 0, Batch 164: Loss = 0.6727 | Acc = 85.55%\n",
      "Epoch 0, Batch 165: Loss = 0.6298 | Acc = 88.67%\n",
      "Epoch 0, Batch 166: Loss = 0.3136 | Acc = 91.02%\n",
      "Epoch 0, Batch 167: Loss = 0.4625 | Acc = 90.62%\n",
      "Epoch 0, Batch 168: Loss = 0.5235 | Acc = 89.45%\n",
      "Epoch 0, Batch 169: Loss = 0.5993 | Acc = 87.50%\n",
      "Epoch 0, Batch 170: Loss = 0.6499 | Acc = 86.72%\n",
      "Epoch 0, Batch 171: Loss = 0.6157 | Acc = 85.94%\n",
      "Epoch 0, Batch 172: Loss = 0.6555 | Acc = 87.11%\n",
      "Epoch 0, Batch 173: Loss = 0.6008 | Acc = 89.45%\n",
      "Epoch 0, Batch 174: Loss = 0.5346 | Acc = 86.72%\n",
      "Epoch 0, Batch 175: Loss = 0.5427 | Acc = 88.67%\n",
      "Epoch 0, Batch 176: Loss = 0.4725 | Acc = 87.89%\n",
      "Epoch 0, Batch 177: Loss = 0.6174 | Acc = 87.11%\n",
      "Epoch 0, Batch 178: Loss = 0.4011 | Acc = 88.28%\n",
      "Epoch 0, Batch 179: Loss = 0.5032 | Acc = 88.28%\n",
      "Epoch 0, Batch 180: Loss = 0.3670 | Acc = 89.45%\n",
      "Epoch 0, Batch 181: Loss = 0.7419 | Acc = 86.33%\n",
      "Epoch 0, Batch 182: Loss = 0.3299 | Acc = 91.41%\n",
      "Epoch 0, Batch 183: Loss = 0.5011 | Acc = 91.80%\n",
      "Epoch 0, Batch 184: Loss = 0.5326 | Acc = 87.11%\n",
      "Epoch 0, Batch 185: Loss = 0.4099 | Acc = 90.23%\n",
      "Epoch 0, Batch 186: Loss = 0.7513 | Acc = 89.06%\n",
      "Epoch 0, Batch 187: Loss = 0.3875 | Acc = 89.06%\n",
      "Epoch 0, Batch 188: Loss = 0.5839 | Acc = 86.72%\n",
      "Epoch 0, Batch 189: Loss = 0.5168 | Acc = 89.84%\n",
      "Epoch 0, Batch 190: Loss = 0.5936 | Acc = 87.50%\n",
      "Epoch 0, Batch 191: Loss = 0.7464 | Acc = 86.72%\n",
      "Epoch 0, Batch 192: Loss = 0.4349 | Acc = 90.23%\n",
      "Epoch 0, Batch 193: Loss = 0.6234 | Acc = 86.72%\n",
      "Epoch 0, Batch 194: Loss = 0.5421 | Acc = 86.33%\n",
      "Epoch 0, Batch 195: Loss = 0.4205 | Acc = 87.89%\n",
      "Epoch 0, Batch 196: Loss = 0.5586 | Acc = 85.55%\n",
      "Epoch 0, Batch 197: Loss = 0.5181 | Acc = 90.23%\n",
      "Epoch 0, Batch 198: Loss = 0.4561 | Acc = 91.02%\n",
      "Epoch 0, Batch 199: Loss = 0.4936 | Acc = 89.45%\n",
      "Epoch 0, Batch 200: Loss = 0.8371 | Acc = 82.81%\n",
      "Epoch 0, Batch 201: Loss = 0.3981 | Acc = 89.84%\n",
      "Epoch 0, Batch 202: Loss = 0.3710 | Acc = 88.67%\n",
      "Epoch 0, Batch 203: Loss = 0.4456 | Acc = 87.11%\n",
      "Epoch 0, Batch 204: Loss = 0.3675 | Acc = 90.62%\n",
      "Epoch 0, Batch 205: Loss = 0.4130 | Acc = 89.84%\n",
      "Epoch 0, Batch 206: Loss = 0.5369 | Acc = 91.80%\n",
      "Epoch 0, Batch 207: Loss = 0.2592 | Acc = 90.23%\n",
      "Epoch 0, Batch 208: Loss = 0.5861 | Acc = 86.72%\n",
      "Epoch 0, Batch 209: Loss = 0.3736 | Acc = 90.23%\n",
      "Epoch 0, Batch 210: Loss = 0.5534 | Acc = 89.84%\n",
      "Epoch 0, Batch 211: Loss = 0.4141 | Acc = 91.02%\n",
      "Epoch 0, Batch 212: Loss = 0.4448 | Acc = 90.23%\n",
      "Epoch 0, Batch 213: Loss = 0.4864 | Acc = 90.23%\n",
      "Epoch 0, Batch 214: Loss = 0.4835 | Acc = 88.28%\n",
      "Epoch 0, Batch 215: Loss = 0.5668 | Acc = 89.06%\n",
      "Epoch 0, Batch 216: Loss = 0.3346 | Acc = 91.02%\n",
      "Epoch 0, Batch 217: Loss = 0.3733 | Acc = 89.06%\n",
      "Epoch 0, Batch 218: Loss = 0.4096 | Acc = 92.19%\n",
      "Epoch 0, Batch 219: Loss = 0.5986 | Acc = 88.28%\n",
      "Epoch 0, Batch 220: Loss = 0.5551 | Acc = 87.50%\n",
      "Epoch 0, Batch 221: Loss = 0.6484 | Acc = 88.28%\n",
      "Epoch 0, Batch 222: Loss = 0.4194 | Acc = 89.84%\n",
      "Epoch 0, Batch 223: Loss = 0.5034 | Acc = 88.67%\n",
      "Epoch 0, Batch 224: Loss = 0.3270 | Acc = 92.58%\n",
      "Epoch 0, Batch 225: Loss = 0.4742 | Acc = 91.02%\n",
      "Epoch 0, Batch 226: Loss = 0.4876 | Acc = 88.28%\n",
      "Epoch 0, Batch 227: Loss = 0.5343 | Acc = 89.45%\n",
      "Epoch 0, Batch 228: Loss = 0.4469 | Acc = 90.23%\n",
      "Epoch 0, Batch 229: Loss = 0.6241 | Acc = 89.06%\n",
      "Epoch 0, Batch 230: Loss = 0.3893 | Acc = 89.06%\n",
      "Epoch 0, Batch 231: Loss = 0.3428 | Acc = 92.19%\n",
      "Epoch 0, Batch 232: Loss = 0.3841 | Acc = 88.28%\n",
      "Epoch 0, Batch 233: Loss = 0.4996 | Acc = 88.28%\n",
      "Epoch 0, Batch 234: Loss = 0.4247 | Acc = 88.54%\n",
      "Model saved to mnist_model_0.pkl\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.95\n",
    "\n",
    "for epoch in range(7):\n",
    "  \n",
    "  lr = 0.1 * np.power(gamma, epoch)\n",
    "  \n",
    "  nn.train(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=1, \n",
    "    learning_rate=lr, \n",
    "    batch_size=256, \n",
    "    decrease_after=100, \n",
    "    gamma=1\n",
    "  )\n",
    "  \n",
    "  save_model(nn, f\"mnist_model_{epoch}.pkl\")\n",
    "  \n",
    "  y_pred = nn.forward_pass(x_test)\n",
    "  curr_test_acc = np.mean(y_pred.argmax(axis=0) == y_test.argmax(axis=0))\n",
    "  \n",
    "  print(f\"Test accuracy for 'mnist_model_{epoch}.pkl': {curr_test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58bb1c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model_0 = load_model(\"mnist_model_0.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a2de792",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.expand_dims(x_test[45, 0, :, :], axis=(0, 1))\n",
    "test_label = y_test[:, 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b605eb7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_data[0][0], cmap=plt.cm.gray)\n",
    "test_label.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "408e3756",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mnist_model_0.forward_pass(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42972356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b95fdcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = range(y_test.shape[1])\n",
    "rand_idx = np.random.choice(idx, size=5000)\n",
    "\n",
    "y_pred = mnist_model_0.forward_pass(x_test[rand_idx, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7867e618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8892)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_pred.argmax(axis=0) == y_test[:, rand_idx].argmax(axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
